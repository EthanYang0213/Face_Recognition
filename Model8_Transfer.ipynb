{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition -Model8\n",
    "\n",
    "使用MTCNN進行人臉偵測\n",
    "\n",
    "使用自建CNN模型進行人臉辨識\n",
    "\n",
    "使用kaggle5位日本明星資料集\n",
    "\n",
    "進行靜態圖像辨識\n",
    "\n",
    "Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "# 將警告訊息關掉\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Utilities相關函式庫\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Python2.X和3.X相容\n",
    "import six\n",
    "\n",
    "# 圖像處理函示庫\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "# 數值處理函式庫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 機器學習函式庫\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 深度學習函式庫\n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Convolution2D, Dropout, Flatten, merge, Reshape, Activation, Lambda, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, add, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.engine import Layer, InputSpec, get_source_inputs\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# 相關參數設定\n",
    "picture_size = 224\n",
    "channel = 3\n",
    "batch_size = 8  # 一次用多少筆資料更新模型\n",
    "num_classes = 6  # 資料集有幾個類別\n",
    "epochs = 300      # 訓練迭代次數\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models') # 儲存模型的路徑\n",
    "model_name = 'Model8_Transfer_VGGFace_V6, trained_model.h5' # 模型名稱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 224, 224, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接讀取處理好的檔案\n",
    "total_img_resized = np.load('total_crop_resized_224.npy')\n",
    "labelnames = np.load('labelnames.npy')\n",
    "total_img_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (416, 224, 224, 3) test: (105, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 切分訓練/測試資料\n",
    "#train_x = total_img\n",
    "#train_y = labelnames\n",
    "\n",
    "train_x,test_x, train_y, test_y = train_test_split(total_img_resized,\n",
    "                                                    labelnames,\n",
    "                                                    test_size = 0.2,stratify= labelnames)#random_state = 123,\n",
    "print('train:',train_x.shape,'test:',test_x.shape)\n",
    "\n",
    "# 正規化資料\n",
    "# 標準化0~255的值到0~1\n",
    "# x_train_normalize = train_x.astype('float32') / 255.0\n",
    "# x_test_normalize = test_x.astype('float32') / 255.0\n",
    "x_train_normalize = preprocess_input(train_x)\n",
    "x_test_normalize = preprocess_input(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 55, 55, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 55, 55, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 55, 55, 256)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 28, 28, 512)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 28, 28, 512)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 28, 28, 512)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 28, 28, 512)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 14, 14, 1024) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 14, 14, 1024) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 14, 14, 1024) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 14, 14, 1024) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 14, 14, 1024) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 14, 14, 1024) 0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 2048)   0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4096)         8392704     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 6)            24582       dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 31,978,438\n",
      "Trainable params: 8,417,286\n",
      "Non-trainable params: 23,561,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning-VGGFace+Resnet50\n",
    "base_model = VGGFace(model='resnet50',include_top=False, input_shape=(picture_size, picture_size, channel))\n",
    "\n",
    "\n",
    "# 凍結基底模型的權重，不更新\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "last_layer = base_model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(4096)(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Dense(num_classes, activation='softmax', name='classifier')(x)\n",
    "model = Model(base_model.input, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "optimizer = Adam(lr=3e-6,decay=0.0001,beta_1=0.99,beta_2=0.999) #100e-6\n",
    "# sgd = keras.optimizers.SGD(lr=1e-6, momentum=0.9, decay=1e-5, nesterov=True)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = optimizer,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen  = ImageDataGenerator(\n",
    "            rotation_range = 30,\n",
    "            width_shift_range = 0.2,\n",
    "            height_shift_range = 0.2,\n",
    "            horizontal_flip = True, \n",
    "            vertical_flip = False,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "104/104 [==============================] - 12s 120ms/step - loss: 1.4400 - acc: 0.5024 - val_loss: 0.6803 - val_acc: 0.7714\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68028, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 2/300\n",
      "104/104 [==============================] - 7s 63ms/step - loss: 0.6657 - acc: 0.7800 - val_loss: 0.3391 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68028 to 0.33913, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 3/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.4518 - acc: 0.8702 - val_loss: 0.2544 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33913 to 0.25439, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 4/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.3330 - acc: 0.9050 - val_loss: 0.2106 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25439 to 0.21062, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 5/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.2930 - acc: 0.9087 - val_loss: 0.1764 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21062 to 0.17638, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 6/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.2575 - acc: 0.9111 - val_loss: 0.1551 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17638 to 0.15508, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 7/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.2494 - acc: 0.9243 - val_loss: 0.1601 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15508\n",
      "Epoch 8/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.2097 - acc: 0.9339 - val_loss: 0.1532 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15508 to 0.15318, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 9/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.2101 - acc: 0.9255 - val_loss: 0.1455 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.15318 to 0.14553, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 10/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.1864 - acc: 0.9387 - val_loss: 0.1462 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.14553\n",
      "Epoch 11/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.2168 - acc: 0.9315 - val_loss: 0.1513 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.14553\n",
      "Epoch 12/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1731 - acc: 0.9423 - val_loss: 0.1414 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.14553 to 0.14141, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 13/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.1594 - acc: 0.9507 - val_loss: 0.1383 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.14141 to 0.13830, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 14/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.1577 - acc: 0.9411 - val_loss: 0.1409 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13830\n",
      "Epoch 15/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1496 - acc: 0.9519 - val_loss: 0.1292 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.13830 to 0.12925, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 16/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1313 - acc: 0.9639 - val_loss: 0.1305 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12925\n",
      "Epoch 17/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1806 - acc: 0.9375 - val_loss: 0.1297 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12925\n",
      "Epoch 18/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1763 - acc: 0.9447 - val_loss: 0.1389 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.12925\n",
      "Epoch 19/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1500 - acc: 0.9519 - val_loss: 0.1301 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.12925\n",
      "Epoch 20/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1296 - acc: 0.9567 - val_loss: 0.1319 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.12925\n",
      "Epoch 21/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1062 - acc: 0.9639 - val_loss: 0.1255 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.12925 to 0.12547, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 22/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.1320 - acc: 0.9603 - val_loss: 0.1289 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.12547\n",
      "Epoch 23/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1337 - acc: 0.9543 - val_loss: 0.1324 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.12547\n",
      "Epoch 24/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0929 - acc: 0.9772 - val_loss: 0.1250 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.12547 to 0.12497, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model8_Transfer_VGGFace_V6, trained_model.h5\n",
      "Epoch 25/300\n",
      "104/104 [==============================] - 7s 65ms/step - loss: 0.1199 - acc: 0.9651 - val_loss: 0.1374 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12497\n",
      "Epoch 26/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1214 - acc: 0.9603 - val_loss: 0.1336 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12497\n",
      "Epoch 27/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1085 - acc: 0.9591 - val_loss: 0.1332 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12497\n",
      "Epoch 28/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1078 - acc: 0.9627 - val_loss: 0.1283 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12497\n",
      "Epoch 29/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1453 - acc: 0.9507 - val_loss: 0.1431 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12497\n",
      "Epoch 30/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1072 - acc: 0.9663 - val_loss: 0.1564 - val_acc: 0.9429\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12497\n",
      "Epoch 31/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1149 - acc: 0.9531 - val_loss: 0.1366 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12497\n",
      "Epoch 32/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1030 - acc: 0.9700 - val_loss: 0.1328 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12497\n",
      "Epoch 33/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0986 - acc: 0.9615 - val_loss: 0.1455 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12497\n",
      "Epoch 34/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1018 - acc: 0.9603 - val_loss: 0.1452 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12497\n",
      "Epoch 35/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1075 - acc: 0.9651 - val_loss: 0.1261 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.12497\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0791 - acc: 0.9736 - val_loss: 0.1331 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.12497\n",
      "Epoch 37/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0746 - acc: 0.9808 - val_loss: 0.1422 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.12497\n",
      "Epoch 38/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0910 - acc: 0.9760 - val_loss: 0.1508 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.12497\n",
      "Epoch 39/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.1055 - acc: 0.9688 - val_loss: 0.1401 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.12497\n",
      "Epoch 40/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0733 - acc: 0.9796 - val_loss: 0.1447 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.12497\n",
      "Epoch 41/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.0837 - acc: 0.9712 - val_loss: 0.1381 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.12497\n",
      "Epoch 42/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1212 - acc: 0.9603 - val_loss: 0.1465 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12497\n",
      "Epoch 43/300\n",
      "104/104 [==============================] - 7s 66ms/step - loss: 0.0987 - acc: 0.9651 - val_loss: 0.1431 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.12497\n",
      "Epoch 44/300\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1033 - acc: 0.9675 - val_loss: 0.1396 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12497\n",
      "Epoch 00044: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Use ModelCheckpoint to save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_loss', save_best_only = True, verbose = 1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 1) # patience=10為連續10次模型loss沒再下降就停止\n",
    "\n",
    "# Fit model\n",
    "aug_ratio = 2\n",
    "steps_per_epoch = int(aug_ratio * train_x.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * test_x.shape[0] / batch_size)\n",
    "\n",
    "model_history = model.fit_generator(datagen.flow(x_train_normalize, train_y, batch_size = batch_size),\n",
    "                                   epochs = epochs,\n",
    "                                   validation_data = (x_test_normalize, test_y),\n",
    "                                   callbacks = [checkpoint, earlystop],\n",
    "                                   steps_per_epoch=steps_per_epoch,\n",
    "                                   validation_steps=validation_steps\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model\n",
      "105/105 [==============================] - 3s 25ms/step\n",
      "Test loss: 0.12497251615637825\n",
      "Test accuracy: 0.9714285719962347\n"
     ]
    }
   ],
   "source": [
    "# loading save model\n",
    "print('Loading trained model')\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Score trained model\n",
    "scores = model.evaluate(x_test_normalize, test_y, verbose = 1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
