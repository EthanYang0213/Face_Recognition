{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition -Model6\n",
    "\n",
    "使用MTCNN進行人臉偵測\n",
    "\n",
    "使用自建CNN模型進行人臉辨識\n",
    "\n",
    "使用kaggle5位日本明星資料集\n",
    "\n",
    "進行靜態圖像辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將警告訊息關掉\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Utilities相關函式庫\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 圖像處理函示庫\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "# 數值處理函式庫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 機器學習函式庫\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 深度學習函式庫\n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, concatenate,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
    "\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "\n",
    "# 人臉偵測函式庫\n",
    "from mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "# 相關參數設定\n",
    "picture_size = 224\n",
    "batch_size = 8  # 一次用多少筆資料更新模型\n",
    "num_classes = 5  # 資料集有幾個類別\n",
    "epochs = 300      # 訓練迭代次數\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models') # 儲存模型的路徑\n",
    "model_name = 'Model6_InceptionV4_V1, trained_model.h5' # 模型名稱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接讀取處理好的檔案\n",
    "total_img_resized = np.load('total_crop_resized.npy')\n",
    "labelnames = np.load('labelnames.npy')\n",
    "total_img_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (403, 224, 224, 3) test: (45, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 切分訓練/測試資料\n",
    "#train_x = total_img\n",
    "#train_y = labelnames\n",
    "\n",
    "train_x,test_x, train_y, test_y = train_test_split(total_img_resized,\n",
    "                                                  labelnames,\n",
    "                                                test_size = 0.1,stratify= labelnames)#random_state = 123,\n",
    "print('train:',train_x.shape,'test:',test_x.shape)\n",
    "\n",
    "# 正規化資料\n",
    "# 標準化0~255的值到0~1\n",
    "x_train_normalize = train_x.astype('float32') / 255.0\n",
    "x_test_normalize = test_x.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 111, 111, 32) 864         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 111, 111, 32) 128         conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_673 (Activation)     (None, 111, 111, 32) 0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 109, 109, 32) 9216        activation_673[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 109, 109, 32) 128         conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_674 (Activation)     (None, 109, 109, 32) 0           batch_normalization_674[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 109, 109, 64) 18432       activation_674[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_675 (BatchN (None, 109, 109, 64) 256         conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_675 (Activation)     (None, 109, 109, 64) 0           batch_normalization_675[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 54, 54, 96)   55296       activation_675[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_676 (BatchN (None, 54, 54, 96)   384         conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling2D) (None, 54, 54, 64)   0           activation_675[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_676 (Activation)     (None, 54, 54, 96)   0           batch_normalization_676[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 54, 54, 160)  0           max_pooling2d_38[0][0]           \n",
      "                                                                 activation_676[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 54, 54, 64)   10240       concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_679 (BatchN (None, 54, 54, 64)   256         conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_679 (Activation)     (None, 54, 54, 64)   0           batch_normalization_679[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 54, 54, 64)   28672       activation_679[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_680 (BatchN (None, 54, 54, 64)   256         conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_680 (Activation)     (None, 54, 54, 64)   0           batch_normalization_680[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_701 (Conv2D)             (None, 54, 54, 64)   10240       concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 54, 54, 64)   28672       activation_680[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_677 (BatchN (None, 54, 54, 64)   256         conv2d_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_681 (BatchN (None, 54, 54, 64)   256         conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_677 (Activation)     (None, 54, 54, 64)   0           batch_normalization_677[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_681 (Activation)     (None, 54, 54, 64)   0           batch_normalization_681[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 52, 52, 96)   55296       activation_677[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 52, 52, 96)   55296       activation_681[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_678 (BatchN (None, 52, 52, 96)   384         conv2d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_682 (BatchN (None, 52, 52, 96)   384         conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_678 (Activation)     (None, 52, 52, 96)   0           batch_normalization_678[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_682 (Activation)     (None, 52, 52, 96)   0           batch_normalization_682[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 52, 52, 192)  0           activation_678[0][0]             \n",
      "                                                                 activation_682[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 25, 25, 192)  331776      concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_683 (BatchN (None, 25, 25, 192)  768         conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_683 (Activation)     (None, 25, 25, 192)  0           batch_normalization_683[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling2D) (None, 25, 25, 192)  0           concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 25, 25, 384)  0           activation_683[0][0]             \n",
      "                                                                 max_pooling2d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_687 (BatchN (None, 25, 25, 64)   192         conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_687 (Activation)     (None, 25, 25, 64)   0           batch_normalization_687[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 25, 25, 96)   55296       activation_687[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_685 (BatchN (None, 25, 25, 64)   192         conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_688 (BatchN (None, 25, 25, 96)   288         conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_685 (Activation)     (None, 25, 25, 64)   0           batch_normalization_685[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_688 (Activation)     (None, 25, 25, 96)   0           batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_65 (AveragePo (None, 25, 25, 384)  0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 25, 25, 96)   36864       concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 25, 25, 96)   55296       activation_685[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 25, 25, 96)   82944       activation_688[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 25, 25, 96)   36864       average_pooling2d_65[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_684 (BatchN (None, 25, 25, 96)   288         conv2d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_686 (BatchN (None, 25, 25, 96)   288         conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_689 (BatchN (None, 25, 25, 96)   288         conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_690 (BatchN (None, 25, 25, 96)   288         conv2d_714[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_684 (Activation)     (None, 25, 25, 96)   0           batch_normalization_684[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_686 (Activation)     (None, 25, 25, 96)   0           batch_normalization_686[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_689 (Activation)     (None, 25, 25, 96)   0           batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_690 (Activation)     (None, 25, 25, 96)   0           batch_normalization_690[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 25, 25, 384)  0           activation_684[0][0]             \n",
      "                                                                 activation_686[0][0]             \n",
      "                                                                 activation_689[0][0]             \n",
      "                                                                 activation_690[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_718 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_694 (BatchN (None, 25, 25, 64)   192         conv2d_718[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_694 (Activation)     (None, 25, 25, 64)   0           batch_normalization_694[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_716 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_719 (Conv2D)             (None, 25, 25, 96)   55296       activation_694[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_692 (BatchN (None, 25, 25, 64)   192         conv2d_716[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_695 (BatchN (None, 25, 25, 96)   288         conv2d_719[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_692 (Activation)     (None, 25, 25, 64)   0           batch_normalization_692[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_695 (Activation)     (None, 25, 25, 96)   0           batch_normalization_695[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_66 (AveragePo (None, 25, 25, 384)  0           concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_715 (Conv2D)             (None, 25, 25, 96)   36864       concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_717 (Conv2D)             (None, 25, 25, 96)   55296       activation_692[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_720 (Conv2D)             (None, 25, 25, 96)   82944       activation_695[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_721 (Conv2D)             (None, 25, 25, 96)   36864       average_pooling2d_66[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_691 (BatchN (None, 25, 25, 96)   288         conv2d_715[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_693 (BatchN (None, 25, 25, 96)   288         conv2d_717[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_696 (BatchN (None, 25, 25, 96)   288         conv2d_720[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_697 (BatchN (None, 25, 25, 96)   288         conv2d_721[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_691 (Activation)     (None, 25, 25, 96)   0           batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_693 (Activation)     (None, 25, 25, 96)   0           batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_696 (Activation)     (None, 25, 25, 96)   0           batch_normalization_696[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_697 (Activation)     (None, 25, 25, 96)   0           batch_normalization_697[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 25, 25, 384)  0           activation_691[0][0]             \n",
      "                                                                 activation_693[0][0]             \n",
      "                                                                 activation_696[0][0]             \n",
      "                                                                 activation_697[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_725 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_701 (BatchN (None, 25, 25, 64)   192         conv2d_725[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_701 (Activation)     (None, 25, 25, 64)   0           batch_normalization_701[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_723 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_726 (Conv2D)             (None, 25, 25, 96)   55296       activation_701[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_699 (BatchN (None, 25, 25, 64)   192         conv2d_723[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_702 (BatchN (None, 25, 25, 96)   288         conv2d_726[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_699 (Activation)     (None, 25, 25, 64)   0           batch_normalization_699[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_702 (Activation)     (None, 25, 25, 96)   0           batch_normalization_702[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_67 (AveragePo (None, 25, 25, 384)  0           concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_722 (Conv2D)             (None, 25, 25, 96)   36864       concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_724 (Conv2D)             (None, 25, 25, 96)   55296       activation_699[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_727 (Conv2D)             (None, 25, 25, 96)   82944       activation_702[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_728 (Conv2D)             (None, 25, 25, 96)   36864       average_pooling2d_67[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_698 (BatchN (None, 25, 25, 96)   288         conv2d_722[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_700 (BatchN (None, 25, 25, 96)   288         conv2d_724[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_703 (BatchN (None, 25, 25, 96)   288         conv2d_727[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_704 (BatchN (None, 25, 25, 96)   288         conv2d_728[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_698 (Activation)     (None, 25, 25, 96)   0           batch_normalization_698[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_700 (Activation)     (None, 25, 25, 96)   0           batch_normalization_700[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_703 (Activation)     (None, 25, 25, 96)   0           batch_normalization_703[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_704 (Activation)     (None, 25, 25, 96)   0           batch_normalization_704[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 25, 25, 384)  0           activation_698[0][0]             \n",
      "                                                                 activation_700[0][0]             \n",
      "                                                                 activation_703[0][0]             \n",
      "                                                                 activation_704[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_732 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_708 (BatchN (None, 25, 25, 64)   192         conv2d_732[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_708 (Activation)     (None, 25, 25, 64)   0           batch_normalization_708[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_730 (Conv2D)             (None, 25, 25, 64)   24576       concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_733 (Conv2D)             (None, 25, 25, 96)   55296       activation_708[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_706 (BatchN (None, 25, 25, 64)   192         conv2d_730[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_709 (BatchN (None, 25, 25, 96)   288         conv2d_733[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_706 (Activation)     (None, 25, 25, 64)   0           batch_normalization_706[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_709 (Activation)     (None, 25, 25, 96)   0           batch_normalization_709[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_68 (AveragePo (None, 25, 25, 384)  0           concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_729 (Conv2D)             (None, 25, 25, 96)   36864       concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_731 (Conv2D)             (None, 25, 25, 96)   55296       activation_706[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_734 (Conv2D)             (None, 25, 25, 96)   82944       activation_709[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_735 (Conv2D)             (None, 25, 25, 96)   36864       average_pooling2d_68[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_705 (BatchN (None, 25, 25, 96)   288         conv2d_729[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_707 (BatchN (None, 25, 25, 96)   288         conv2d_731[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_710 (BatchN (None, 25, 25, 96)   288         conv2d_734[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_711 (BatchN (None, 25, 25, 96)   288         conv2d_735[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_705 (Activation)     (None, 25, 25, 96)   0           batch_normalization_705[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_707 (Activation)     (None, 25, 25, 96)   0           batch_normalization_707[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_710 (Activation)     (None, 25, 25, 96)   0           batch_normalization_710[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_711 (Activation)     (None, 25, 25, 96)   0           batch_normalization_711[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 25, 25, 384)  0           activation_705[0][0]             \n",
      "                                                                 activation_707[0][0]             \n",
      "                                                                 activation_710[0][0]             \n",
      "                                                                 activation_711[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_737 (Conv2D)             (None, 25, 25, 192)  73728       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_713 (BatchN (None, 25, 25, 192)  576         conv2d_737[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_713 (Activation)     (None, 25, 25, 192)  0           batch_normalization_713[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_738 (Conv2D)             (None, 25, 25, 224)  387072      activation_713[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_714 (BatchN (None, 25, 25, 224)  672         conv2d_738[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_714 (Activation)     (None, 25, 25, 224)  0           batch_normalization_714[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_736 (Conv2D)             (None, 12, 12, 384)  1327104     concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_739 (Conv2D)             (None, 12, 12, 256)  516096      activation_714[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_712 (BatchN (None, 12, 12, 384)  1152        conv2d_736[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_715 (BatchN (None, 12, 12, 256)  768         conv2d_739[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_712 (Activation)     (None, 12, 12, 384)  0           batch_normalization_712[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_715 (Activation)     (None, 12, 12, 256)  0           batch_normalization_715[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling2D) (None, 12, 12, 384)  0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 12, 12, 1024) 0           activation_712[0][0]             \n",
      "                                                                 activation_715[0][0]             \n",
      "                                                                 max_pooling2d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_744 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_720 (BatchN (None, 12, 12, 192)  576         conv2d_744[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_720 (Activation)     (None, 12, 12, 192)  0           batch_normalization_720[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_745 (Conv2D)             (None, 12, 12, 192)  258048      activation_720[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_721 (BatchN (None, 12, 12, 192)  576         conv2d_745[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_721 (Activation)     (None, 12, 12, 192)  0           batch_normalization_721[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_741 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_746 (Conv2D)             (None, 12, 12, 224)  301056      activation_721[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_717 (BatchN (None, 12, 12, 192)  576         conv2d_741[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_722 (BatchN (None, 12, 12, 224)  672         conv2d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_717 (Activation)     (None, 12, 12, 192)  0           batch_normalization_717[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_722 (Activation)     (None, 12, 12, 224)  0           batch_normalization_722[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_742 (Conv2D)             (None, 12, 12, 224)  301056      activation_717[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_747 (Conv2D)             (None, 12, 12, 224)  351232      activation_722[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_718 (BatchN (None, 12, 12, 224)  672         conv2d_742[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_723 (BatchN (None, 12, 12, 224)  672         conv2d_747[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_718 (Activation)     (None, 12, 12, 224)  0           batch_normalization_718[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_723 (Activation)     (None, 12, 12, 224)  0           batch_normalization_723[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_69 (AveragePo (None, 12, 12, 1024) 0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_740 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_743 (Conv2D)             (None, 12, 12, 256)  401408      activation_718[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_748 (Conv2D)             (None, 12, 12, 256)  401408      activation_723[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_749 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_69[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_716 (BatchN (None, 12, 12, 384)  1152        conv2d_740[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_719 (BatchN (None, 12, 12, 256)  768         conv2d_743[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_724 (BatchN (None, 12, 12, 256)  768         conv2d_748[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_725 (BatchN (None, 12, 12, 128)  384         conv2d_749[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_716 (Activation)     (None, 12, 12, 384)  0           batch_normalization_716[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_719 (Activation)     (None, 12, 12, 256)  0           batch_normalization_719[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_724 (Activation)     (None, 12, 12, 256)  0           batch_normalization_724[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_725 (Activation)     (None, 12, 12, 128)  0           batch_normalization_725[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 12, 12, 1024) 0           activation_716[0][0]             \n",
      "                                                                 activation_719[0][0]             \n",
      "                                                                 activation_724[0][0]             \n",
      "                                                                 activation_725[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_754 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_730 (BatchN (None, 12, 12, 192)  576         conv2d_754[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_730 (Activation)     (None, 12, 12, 192)  0           batch_normalization_730[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_755 (Conv2D)             (None, 12, 12, 192)  258048      activation_730[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_731 (BatchN (None, 12, 12, 192)  576         conv2d_755[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_731 (Activation)     (None, 12, 12, 192)  0           batch_normalization_731[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_751 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_756 (Conv2D)             (None, 12, 12, 224)  301056      activation_731[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_727 (BatchN (None, 12, 12, 192)  576         conv2d_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_732 (BatchN (None, 12, 12, 224)  672         conv2d_756[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_727 (Activation)     (None, 12, 12, 192)  0           batch_normalization_727[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_732 (Activation)     (None, 12, 12, 224)  0           batch_normalization_732[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_752 (Conv2D)             (None, 12, 12, 224)  301056      activation_727[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_757 (Conv2D)             (None, 12, 12, 224)  351232      activation_732[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_728 (BatchN (None, 12, 12, 224)  672         conv2d_752[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_733 (BatchN (None, 12, 12, 224)  672         conv2d_757[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_728 (Activation)     (None, 12, 12, 224)  0           batch_normalization_728[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_733 (Activation)     (None, 12, 12, 224)  0           batch_normalization_733[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_70 (AveragePo (None, 12, 12, 1024) 0           concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_750 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_753 (Conv2D)             (None, 12, 12, 256)  401408      activation_728[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_758 (Conv2D)             (None, 12, 12, 256)  401408      activation_733[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_759 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_70[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_726 (BatchN (None, 12, 12, 384)  1152        conv2d_750[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_729 (BatchN (None, 12, 12, 256)  768         conv2d_753[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_734 (BatchN (None, 12, 12, 256)  768         conv2d_758[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_735 (BatchN (None, 12, 12, 128)  384         conv2d_759[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_726 (Activation)     (None, 12, 12, 384)  0           batch_normalization_726[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_729 (Activation)     (None, 12, 12, 256)  0           batch_normalization_729[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_734 (Activation)     (None, 12, 12, 256)  0           batch_normalization_734[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_735 (Activation)     (None, 12, 12, 128)  0           batch_normalization_735[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 12, 12, 1024) 0           activation_726[0][0]             \n",
      "                                                                 activation_729[0][0]             \n",
      "                                                                 activation_734[0][0]             \n",
      "                                                                 activation_735[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_764 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_740 (BatchN (None, 12, 12, 192)  576         conv2d_764[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_740 (Activation)     (None, 12, 12, 192)  0           batch_normalization_740[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_765 (Conv2D)             (None, 12, 12, 192)  258048      activation_740[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_741 (BatchN (None, 12, 12, 192)  576         conv2d_765[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_741 (Activation)     (None, 12, 12, 192)  0           batch_normalization_741[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_761 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_766 (Conv2D)             (None, 12, 12, 224)  301056      activation_741[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_737 (BatchN (None, 12, 12, 192)  576         conv2d_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_742 (BatchN (None, 12, 12, 224)  672         conv2d_766[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_737 (Activation)     (None, 12, 12, 192)  0           batch_normalization_737[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_742 (Activation)     (None, 12, 12, 224)  0           batch_normalization_742[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_762 (Conv2D)             (None, 12, 12, 224)  301056      activation_737[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_767 (Conv2D)             (None, 12, 12, 224)  351232      activation_742[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_738 (BatchN (None, 12, 12, 224)  672         conv2d_762[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_743 (BatchN (None, 12, 12, 224)  672         conv2d_767[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_738 (Activation)     (None, 12, 12, 224)  0           batch_normalization_738[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_743 (Activation)     (None, 12, 12, 224)  0           batch_normalization_743[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_71 (AveragePo (None, 12, 12, 1024) 0           concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_760 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_763 (Conv2D)             (None, 12, 12, 256)  401408      activation_738[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_768 (Conv2D)             (None, 12, 12, 256)  401408      activation_743[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_769 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_71[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_736 (BatchN (None, 12, 12, 384)  1152        conv2d_760[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_739 (BatchN (None, 12, 12, 256)  768         conv2d_763[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_744 (BatchN (None, 12, 12, 256)  768         conv2d_768[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_745 (BatchN (None, 12, 12, 128)  384         conv2d_769[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_736 (Activation)     (None, 12, 12, 384)  0           batch_normalization_736[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_739 (Activation)     (None, 12, 12, 256)  0           batch_normalization_739[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_744 (Activation)     (None, 12, 12, 256)  0           batch_normalization_744[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_745 (Activation)     (None, 12, 12, 128)  0           batch_normalization_745[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 12, 12, 1024) 0           activation_736[0][0]             \n",
      "                                                                 activation_739[0][0]             \n",
      "                                                                 activation_744[0][0]             \n",
      "                                                                 activation_745[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_774 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_750 (BatchN (None, 12, 12, 192)  576         conv2d_774[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_750 (Activation)     (None, 12, 12, 192)  0           batch_normalization_750[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_775 (Conv2D)             (None, 12, 12, 192)  258048      activation_750[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_751 (BatchN (None, 12, 12, 192)  576         conv2d_775[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_751 (Activation)     (None, 12, 12, 192)  0           batch_normalization_751[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_771 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_776 (Conv2D)             (None, 12, 12, 224)  301056      activation_751[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_747 (BatchN (None, 12, 12, 192)  576         conv2d_771[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_752 (BatchN (None, 12, 12, 224)  672         conv2d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_747 (Activation)     (None, 12, 12, 192)  0           batch_normalization_747[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_752 (Activation)     (None, 12, 12, 224)  0           batch_normalization_752[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_772 (Conv2D)             (None, 12, 12, 224)  301056      activation_747[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_777 (Conv2D)             (None, 12, 12, 224)  351232      activation_752[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_748 (BatchN (None, 12, 12, 224)  672         conv2d_772[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_753 (BatchN (None, 12, 12, 224)  672         conv2d_777[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_748 (Activation)     (None, 12, 12, 224)  0           batch_normalization_748[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_753 (Activation)     (None, 12, 12, 224)  0           batch_normalization_753[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_72 (AveragePo (None, 12, 12, 1024) 0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_770 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_773 (Conv2D)             (None, 12, 12, 256)  401408      activation_748[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_778 (Conv2D)             (None, 12, 12, 256)  401408      activation_753[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_779 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_72[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_746 (BatchN (None, 12, 12, 384)  1152        conv2d_770[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_749 (BatchN (None, 12, 12, 256)  768         conv2d_773[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_754 (BatchN (None, 12, 12, 256)  768         conv2d_778[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_755 (BatchN (None, 12, 12, 128)  384         conv2d_779[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_746 (Activation)     (None, 12, 12, 384)  0           batch_normalization_746[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_749 (Activation)     (None, 12, 12, 256)  0           batch_normalization_749[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_754 (Activation)     (None, 12, 12, 256)  0           batch_normalization_754[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_755 (Activation)     (None, 12, 12, 128)  0           batch_normalization_755[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 12, 12, 1024) 0           activation_746[0][0]             \n",
      "                                                                 activation_749[0][0]             \n",
      "                                                                 activation_754[0][0]             \n",
      "                                                                 activation_755[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_784 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchN (None, 12, 12, 192)  576         conv2d_784[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_760 (Activation)     (None, 12, 12, 192)  0           batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_785 (Conv2D)             (None, 12, 12, 192)  258048      activation_760[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchN (None, 12, 12, 192)  576         conv2d_785[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_761 (Activation)     (None, 12, 12, 192)  0           batch_normalization_761[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_781 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_786 (Conv2D)             (None, 12, 12, 224)  301056      activation_761[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchN (None, 12, 12, 192)  576         conv2d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchN (None, 12, 12, 224)  672         conv2d_786[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_757 (Activation)     (None, 12, 12, 192)  0           batch_normalization_757[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_762 (Activation)     (None, 12, 12, 224)  0           batch_normalization_762[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_782 (Conv2D)             (None, 12, 12, 224)  301056      activation_757[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_787 (Conv2D)             (None, 12, 12, 224)  351232      activation_762[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchN (None, 12, 12, 224)  672         conv2d_782[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_763 (BatchN (None, 12, 12, 224)  672         conv2d_787[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_758 (Activation)     (None, 12, 12, 224)  0           batch_normalization_758[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_763 (Activation)     (None, 12, 12, 224)  0           batch_normalization_763[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_73 (AveragePo (None, 12, 12, 1024) 0           concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_780 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_783 (Conv2D)             (None, 12, 12, 256)  401408      activation_758[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_788 (Conv2D)             (None, 12, 12, 256)  401408      activation_763[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_789 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_73[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchN (None, 12, 12, 384)  1152        conv2d_780[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchN (None, 12, 12, 256)  768         conv2d_783[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_764 (BatchN (None, 12, 12, 256)  768         conv2d_788[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_765 (BatchN (None, 12, 12, 128)  384         conv2d_789[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_756 (Activation)     (None, 12, 12, 384)  0           batch_normalization_756[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_759 (Activation)     (None, 12, 12, 256)  0           batch_normalization_759[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_764 (Activation)     (None, 12, 12, 256)  0           batch_normalization_764[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_765 (Activation)     (None, 12, 12, 128)  0           batch_normalization_765[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 12, 12, 1024) 0           activation_756[0][0]             \n",
      "                                                                 activation_759[0][0]             \n",
      "                                                                 activation_764[0][0]             \n",
      "                                                                 activation_765[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_794 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_770 (BatchN (None, 12, 12, 192)  576         conv2d_794[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_770 (Activation)     (None, 12, 12, 192)  0           batch_normalization_770[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_795 (Conv2D)             (None, 12, 12, 192)  258048      activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_771 (BatchN (None, 12, 12, 192)  576         conv2d_795[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_771 (Activation)     (None, 12, 12, 192)  0           batch_normalization_771[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_791 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_796 (Conv2D)             (None, 12, 12, 224)  301056      activation_771[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_767 (BatchN (None, 12, 12, 192)  576         conv2d_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_772 (BatchN (None, 12, 12, 224)  672         conv2d_796[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_767 (Activation)     (None, 12, 12, 192)  0           batch_normalization_767[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_772 (Activation)     (None, 12, 12, 224)  0           batch_normalization_772[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_792 (Conv2D)             (None, 12, 12, 224)  301056      activation_767[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_797 (Conv2D)             (None, 12, 12, 224)  351232      activation_772[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_768 (BatchN (None, 12, 12, 224)  672         conv2d_792[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_773 (BatchN (None, 12, 12, 224)  672         conv2d_797[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_768 (Activation)     (None, 12, 12, 224)  0           batch_normalization_768[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_773 (Activation)     (None, 12, 12, 224)  0           batch_normalization_773[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_74 (AveragePo (None, 12, 12, 1024) 0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_790 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_793 (Conv2D)             (None, 12, 12, 256)  401408      activation_768[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_798 (Conv2D)             (None, 12, 12, 256)  401408      activation_773[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_799 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_74[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_766 (BatchN (None, 12, 12, 384)  1152        conv2d_790[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_769 (BatchN (None, 12, 12, 256)  768         conv2d_793[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_774 (BatchN (None, 12, 12, 256)  768         conv2d_798[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_775 (BatchN (None, 12, 12, 128)  384         conv2d_799[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_766 (Activation)     (None, 12, 12, 384)  0           batch_normalization_766[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_769 (Activation)     (None, 12, 12, 256)  0           batch_normalization_769[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_774 (Activation)     (None, 12, 12, 256)  0           batch_normalization_774[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_775 (Activation)     (None, 12, 12, 128)  0           batch_normalization_775[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 12, 12, 1024) 0           activation_766[0][0]             \n",
      "                                                                 activation_769[0][0]             \n",
      "                                                                 activation_774[0][0]             \n",
      "                                                                 activation_775[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_804 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_780 (BatchN (None, 12, 12, 192)  576         conv2d_804[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_780 (Activation)     (None, 12, 12, 192)  0           batch_normalization_780[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_805 (Conv2D)             (None, 12, 12, 192)  258048      activation_780[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_781 (BatchN (None, 12, 12, 192)  576         conv2d_805[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_781 (Activation)     (None, 12, 12, 192)  0           batch_normalization_781[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_801 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_806 (Conv2D)             (None, 12, 12, 224)  301056      activation_781[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_777 (BatchN (None, 12, 12, 192)  576         conv2d_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_782 (BatchN (None, 12, 12, 224)  672         conv2d_806[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_777 (Activation)     (None, 12, 12, 192)  0           batch_normalization_777[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_782 (Activation)     (None, 12, 12, 224)  0           batch_normalization_782[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_802 (Conv2D)             (None, 12, 12, 224)  301056      activation_777[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_807 (Conv2D)             (None, 12, 12, 224)  351232      activation_782[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_778 (BatchN (None, 12, 12, 224)  672         conv2d_802[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_783 (BatchN (None, 12, 12, 224)  672         conv2d_807[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_778 (Activation)     (None, 12, 12, 224)  0           batch_normalization_778[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_783 (Activation)     (None, 12, 12, 224)  0           batch_normalization_783[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_75 (AveragePo (None, 12, 12, 1024) 0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_800 (Conv2D)             (None, 12, 12, 384)  393216      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_803 (Conv2D)             (None, 12, 12, 256)  401408      activation_778[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_808 (Conv2D)             (None, 12, 12, 256)  401408      activation_783[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_809 (Conv2D)             (None, 12, 12, 128)  131072      average_pooling2d_75[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_776 (BatchN (None, 12, 12, 384)  1152        conv2d_800[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_779 (BatchN (None, 12, 12, 256)  768         conv2d_803[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_784 (BatchN (None, 12, 12, 256)  768         conv2d_808[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_785 (BatchN (None, 12, 12, 128)  384         conv2d_809[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_776 (Activation)     (None, 12, 12, 384)  0           batch_normalization_776[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_779 (Activation)     (None, 12, 12, 256)  0           batch_normalization_779[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_784 (Activation)     (None, 12, 12, 256)  0           batch_normalization_784[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_785 (Activation)     (None, 12, 12, 128)  0           batch_normalization_785[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 12, 12, 1024) 0           activation_776[0][0]             \n",
      "                                                                 activation_779[0][0]             \n",
      "                                                                 activation_784[0][0]             \n",
      "                                                                 activation_785[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_812 (Conv2D)             (None, 12, 12, 256)  262144      concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_788 (BatchN (None, 12, 12, 256)  768         conv2d_812[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_788 (Activation)     (None, 12, 12, 256)  0           batch_normalization_788[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_813 (Conv2D)             (None, 12, 12, 256)  458752      activation_788[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_789 (BatchN (None, 12, 12, 256)  768         conv2d_813[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_789 (Activation)     (None, 12, 12, 256)  0           batch_normalization_789[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_810 (Conv2D)             (None, 12, 12, 192)  196608      concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_814 (Conv2D)             (None, 12, 12, 320)  573440      activation_789[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_786 (BatchN (None, 12, 12, 192)  576         conv2d_810[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_790 (BatchN (None, 12, 12, 320)  960         conv2d_814[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_786 (Activation)     (None, 12, 12, 192)  0           batch_normalization_786[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_790 (Activation)     (None, 12, 12, 320)  0           batch_normalization_790[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_811 (Conv2D)             (None, 5, 5, 192)    331776      activation_786[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_815 (Conv2D)             (None, 5, 5, 320)    921600      activation_790[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_787 (BatchN (None, 5, 5, 192)    576         conv2d_811[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_791 (BatchN (None, 5, 5, 320)    960         conv2d_815[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_787 (Activation)     (None, 5, 5, 192)    0           batch_normalization_787[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_791 (Activation)     (None, 5, 5, 320)    0           batch_normalization_791[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling2D) (None, 5, 5, 1024)   0           concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 5, 5, 1536)   0           activation_787[0][0]             \n",
      "                                                                 activation_791[0][0]             \n",
      "                                                                 max_pooling2d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_820 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_796 (BatchN (None, 5, 5, 384)    1152        conv2d_820[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_796 (Activation)     (None, 5, 5, 384)    0           batch_normalization_796[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_821 (Conv2D)             (None, 5, 5, 448)    516096      activation_796[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_797 (BatchN (None, 5, 5, 448)    1344        conv2d_821[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_797 (Activation)     (None, 5, 5, 448)    0           batch_normalization_797[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_817 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_822 (Conv2D)             (None, 5, 5, 512)    688128      activation_797[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_793 (BatchN (None, 5, 5, 384)    1152        conv2d_817[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_798 (BatchN (None, 5, 5, 512)    1536        conv2d_822[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_793 (Activation)     (None, 5, 5, 384)    0           batch_normalization_793[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_798 (Activation)     (None, 5, 5, 512)    0           batch_normalization_798[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_818 (Conv2D)             (None, 5, 5, 256)    294912      activation_793[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_819 (Conv2D)             (None, 5, 5, 256)    294912      activation_793[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_823 (Conv2D)             (None, 5, 5, 256)    393216      activation_798[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_824 (Conv2D)             (None, 5, 5, 256)    393216      activation_798[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_76 (AveragePo (None, 5, 5, 1536)   0           concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_816 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_794 (BatchN (None, 5, 5, 256)    768         conv2d_818[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_795 (BatchN (None, 5, 5, 256)    768         conv2d_819[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_799 (BatchN (None, 5, 5, 256)    768         conv2d_823[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_800 (BatchN (None, 5, 5, 256)    768         conv2d_824[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_825 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_76[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_792 (BatchN (None, 5, 5, 256)    768         conv2d_816[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_794 (Activation)     (None, 5, 5, 256)    0           batch_normalization_794[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_795 (Activation)     (None, 5, 5, 256)    0           batch_normalization_795[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_799 (Activation)     (None, 5, 5, 256)    0           batch_normalization_799[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_800 (Activation)     (None, 5, 5, 256)    0           batch_normalization_800[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_801 (BatchN (None, 5, 5, 256)    768         conv2d_825[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_792 (Activation)     (None, 5, 5, 256)    0           batch_normalization_792[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 5, 5, 512)    0           activation_794[0][0]             \n",
      "                                                                 activation_795[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 5, 5, 512)    0           activation_799[0][0]             \n",
      "                                                                 activation_800[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_801 (Activation)     (None, 5, 5, 256)    0           batch_normalization_801[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 5, 5, 1536)   0           activation_792[0][0]             \n",
      "                                                                 concatenate_110[0][0]            \n",
      "                                                                 concatenate_111[0][0]            \n",
      "                                                                 activation_801[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_830 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_806 (BatchN (None, 5, 5, 384)    1152        conv2d_830[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_806 (Activation)     (None, 5, 5, 384)    0           batch_normalization_806[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_831 (Conv2D)             (None, 5, 5, 448)    516096      activation_806[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_807 (BatchN (None, 5, 5, 448)    1344        conv2d_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_807 (Activation)     (None, 5, 5, 448)    0           batch_normalization_807[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_827 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_832 (Conv2D)             (None, 5, 5, 512)    688128      activation_807[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_803 (BatchN (None, 5, 5, 384)    1152        conv2d_827[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_808 (BatchN (None, 5, 5, 512)    1536        conv2d_832[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_803 (Activation)     (None, 5, 5, 384)    0           batch_normalization_803[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_808 (Activation)     (None, 5, 5, 512)    0           batch_normalization_808[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_828 (Conv2D)             (None, 5, 5, 256)    294912      activation_803[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_829 (Conv2D)             (None, 5, 5, 256)    294912      activation_803[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_833 (Conv2D)             (None, 5, 5, 256)    393216      activation_808[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_834 (Conv2D)             (None, 5, 5, 256)    393216      activation_808[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_77 (AveragePo (None, 5, 5, 1536)   0           concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_826 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_804 (BatchN (None, 5, 5, 256)    768         conv2d_828[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_805 (BatchN (None, 5, 5, 256)    768         conv2d_829[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_809 (BatchN (None, 5, 5, 256)    768         conv2d_833[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_810 (BatchN (None, 5, 5, 256)    768         conv2d_834[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_835 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_77[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_802 (BatchN (None, 5, 5, 256)    768         conv2d_826[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_804 (Activation)     (None, 5, 5, 256)    0           batch_normalization_804[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_805 (Activation)     (None, 5, 5, 256)    0           batch_normalization_805[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_809 (Activation)     (None, 5, 5, 256)    0           batch_normalization_809[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_810 (Activation)     (None, 5, 5, 256)    0           batch_normalization_810[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_811 (BatchN (None, 5, 5, 256)    768         conv2d_835[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_802 (Activation)     (None, 5, 5, 256)    0           batch_normalization_802[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 5, 5, 512)    0           activation_804[0][0]             \n",
      "                                                                 activation_805[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 5, 5, 512)    0           activation_809[0][0]             \n",
      "                                                                 activation_810[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_811 (Activation)     (None, 5, 5, 256)    0           batch_normalization_811[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 5, 5, 1536)   0           activation_802[0][0]             \n",
      "                                                                 concatenate_113[0][0]            \n",
      "                                                                 concatenate_114[0][0]            \n",
      "                                                                 activation_811[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_840 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_816 (BatchN (None, 5, 5, 384)    1152        conv2d_840[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_816 (Activation)     (None, 5, 5, 384)    0           batch_normalization_816[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_841 (Conv2D)             (None, 5, 5, 448)    516096      activation_816[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_817 (BatchN (None, 5, 5, 448)    1344        conv2d_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_817 (Activation)     (None, 5, 5, 448)    0           batch_normalization_817[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_837 (Conv2D)             (None, 5, 5, 384)    589824      concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_842 (Conv2D)             (None, 5, 5, 512)    688128      activation_817[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_813 (BatchN (None, 5, 5, 384)    1152        conv2d_837[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_818 (BatchN (None, 5, 5, 512)    1536        conv2d_842[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_813 (Activation)     (None, 5, 5, 384)    0           batch_normalization_813[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_818 (Activation)     (None, 5, 5, 512)    0           batch_normalization_818[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_838 (Conv2D)             (None, 5, 5, 256)    294912      activation_813[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_839 (Conv2D)             (None, 5, 5, 256)    294912      activation_813[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_843 (Conv2D)             (None, 5, 5, 256)    393216      activation_818[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_844 (Conv2D)             (None, 5, 5, 256)    393216      activation_818[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_78 (AveragePo (None, 5, 5, 1536)   0           concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_836 (Conv2D)             (None, 5, 5, 256)    393216      concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_814 (BatchN (None, 5, 5, 256)    768         conv2d_838[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_815 (BatchN (None, 5, 5, 256)    768         conv2d_839[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_819 (BatchN (None, 5, 5, 256)    768         conv2d_843[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_820 (BatchN (None, 5, 5, 256)    768         conv2d_844[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_845 (Conv2D)             (None, 5, 5, 256)    393216      average_pooling2d_78[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_812 (BatchN (None, 5, 5, 256)    768         conv2d_836[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_814 (Activation)     (None, 5, 5, 256)    0           batch_normalization_814[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_815 (Activation)     (None, 5, 5, 256)    0           batch_normalization_815[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_819 (Activation)     (None, 5, 5, 256)    0           batch_normalization_819[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_820 (Activation)     (None, 5, 5, 256)    0           batch_normalization_820[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_821 (BatchN (None, 5, 5, 256)    768         conv2d_845[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_812 (Activation)     (None, 5, 5, 256)    0           batch_normalization_812[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 5, 5, 512)    0           activation_814[0][0]             \n",
      "                                                                 activation_815[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 5, 5, 512)    0           activation_819[0][0]             \n",
      "                                                                 activation_820[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_821 (Activation)     (None, 5, 5, 256)    0           batch_normalization_821[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 5, 5, 1536)   0           activation_812[0][0]             \n",
      "                                                                 concatenate_116[0][0]            \n",
      "                                                                 concatenate_117[0][0]            \n",
      "                                                                 activation_821[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_79 (AveragePo (None, 2, 2, 1536)   0           concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 6144)         0           average_pooling2d_79[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 5)            30725       flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,205,989\n",
      "Trainable params: 41,142,821\n",
      "Non-trainable params: 63,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GoogLeNet-Inception-V4\n",
    "# WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "# WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "              padding='same', strides=(1, 1), use_bias=False):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN. \n",
    "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    x = Conv2D(nb_filter, (num_row, num_col),\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias,\n",
    "                      kernel_regularizer=regularizers.l2(0.00004),\n",
    "                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_c(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
    "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
    "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_v4_base(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
    "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "    \tnet = block_inception_a(net)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "    \tnet = block_inception_b(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    # 3 x Inception-C blocks\n",
    "    for idx in range(3):\n",
    "    \tnet = block_inception_c(net)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
    "    '''\n",
    "    Creates the inception v4 network\n",
    "    Args:\n",
    "    \tnum_classes: number of classes\n",
    "    \tdropout_keep_prob: float, the fraction to keep before final layer.\n",
    "    \n",
    "    Returns: \n",
    "    \tlogits: the logits outputs of the model.\n",
    "    '''\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputs = Input((3, 299, 299))\n",
    "    else:\n",
    "        inputs = Input((299, 299, 3))\n",
    "\n",
    "    # Make inception base\n",
    "    x = inception_v4_base(inputs)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "    if include_top:\n",
    "        # 1 x 1 x 1536\n",
    "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
    "        x = Dropout(dropout_keep_prob)(x)\n",
    "        x = Flatten()(x)\n",
    "        # 1536\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='inception_v4')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "        if include_top:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
    "        else:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9296b46b5971573064d12e4669110969')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(num_classes=5, dropout_prob=0.2, weights=None, include_top=False):\n",
    "    return inception_v4(num_classes, dropout_prob, weights, include_top)\n",
    "\n",
    "\n",
    "model = create()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "optimizer = Adam(lr=3e-6,decay=0.0001,beta_1=0.99,beta_2=0.999) #100e-6\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = optimizer,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen  = ImageDataGenerator(\n",
    "            rotation_range = 30,\n",
    "            width_shift_range = 0.2,\n",
    "            height_shift_range = 0.2,\n",
    "            horizontal_flip = True, \n",
    "            vertical_flip = False,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "100/100 [==============================] - 53s 530ms/step - loss: 4.1420 - acc: 0.2263 - val_loss: 4.6109 - val_acc: 0.2667\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.61092, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model6_InceptionV4_V1, trained_model.h5\n",
      "Epoch 2/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0837 - acc: 0.2463 - val_loss: 4.7221 - val_acc: 0.2444\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.61092\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0733 - acc: 0.2558 - val_loss: 4.9979 - val_acc: 0.2889\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.61092\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0950 - acc: 0.2854 - val_loss: 4.5728 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.61092 to 4.57280, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model6_InceptionV4_V1, trained_model.h5\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0382 - acc: 0.3121 - val_loss: 4.6203 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.57280\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0509 - acc: 0.2863 - val_loss: 4.6759 - val_acc: 0.2889\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.57280\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0450 - acc: 0.3100 - val_loss: 4.5850 - val_acc: 0.2444\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.57280\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0236 - acc: 0.3187 - val_loss: 4.6249 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.57280\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0412 - acc: 0.3029 - val_loss: 4.5057 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.57280 to 4.50569, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model6_InceptionV4_V1, trained_model.h5\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0338 - acc: 0.2954 - val_loss: 4.6947 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.50569\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0513 - acc: 0.2821 - val_loss: 4.4452 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.50569 to 4.44518, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model6_InceptionV4_V1, trained_model.h5\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 4.0116 - acc: 0.3071 - val_loss: 4.4226 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.44518 to 4.42263, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model6_InceptionV4_V1, trained_model.h5\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 3.9953 - acc: 0.3354 - val_loss: 4.5526 - val_acc: 0.2889\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.42263\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 4.0235 - acc: 0.3084 - val_loss: 4.2845 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.42263 to 4.28447, saving model to C:\\Users\\foresight\\Desktop\\AI\\Face Recognition\\saved_models\\Model6_InceptionV4_V1, trained_model.h5\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 3.9765 - acc: 0.3404 - val_loss: 4.4609 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.28447\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0299 - acc: 0.3125 - val_loss: 4.3305 - val_acc: 0.3778\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.28447\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 3.9931 - acc: 0.3454 - val_loss: 4.3950 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.28447\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 3.9717 - acc: 0.3409 - val_loss: 4.7912 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.28447\n",
      "Epoch 19/300\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 4.0026 - acc: 0.3354 - val_loss: 4.8585 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.28447\n",
      "Epoch 20/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 3.9872 - acc: 0.3438 - val_loss: 4.6708 - val_acc: 0.3778\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.28447\n",
      "Epoch 21/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 4.0002 - acc: 0.3288 - val_loss: 4.8082 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.28447\n",
      "Epoch 22/300\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 3.9508 - acc: 0.3809 - val_loss: 4.5526 - val_acc: 0.2889\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.28447\n",
      "Epoch 23/300\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 3.9857 - acc: 0.3554 - val_loss: 4.3950 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.28447\n",
      "Epoch 24/300\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 3.9726 - acc: 0.3375 - val_loss: 4.3261 - val_acc: 0.4000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.28447\n",
      "Epoch 25/300\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 3.9617 - acc: 0.3634 - val_loss: 4.7672 - val_acc: 0.2667\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.28447\n",
      "Epoch 26/300\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 3.9686 - acc: 0.3671 - val_loss: 4.4856 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.28447\n",
      "Epoch 27/300\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 3.9651 - acc: 0.3629 - val_loss: 4.6110 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.28447\n",
      "Epoch 28/300\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 3.9305 - acc: 0.3925 - val_loss: 4.7918 - val_acc: 0.2889\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.28447\n",
      "Epoch 29/300\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 3.9227 - acc: 0.3987 - val_loss: 4.5840 - val_acc: 0.2444\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.28447\n",
      "Epoch 30/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 3.9366 - acc: 0.3787 - val_loss: 4.5454 - val_acc: 0.2667\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.28447\n",
      "Epoch 31/300\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 3.9414 - acc: 0.3579 - val_loss: 4.5023 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.28447\n",
      "Epoch 32/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 3.9858 - acc: 0.3275 - val_loss: 4.5506 - val_acc: 0.3111\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.28447\n",
      "Epoch 33/300\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 3.9617 - acc: 0.3721 - val_loss: 4.8177 - val_acc: 0.3333\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4.28447\n",
      "Epoch 34/300\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 3.9266 - acc: 0.3825 - val_loss: 4.3447 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.28447\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Use ModelCheckpoint to save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor = 'val_loss', save_best_only = True, verbose = 1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', patience = 20, verbose = 1) # patience=10為連續10次模型loss沒再下降就停止\n",
    "\n",
    "# Fit model\n",
    "aug_ratio = 2\n",
    "steps_per_epoch = int(aug_ratio * train_x.shape[0] / batch_size)\n",
    "validation_steps = int(aug_ratio * test_x.shape[0] / batch_size)\n",
    "\n",
    "model_history = model.fit_generator(datagen.flow(x_train_normalize, train_y, batch_size = batch_size),\n",
    "                                   epochs = epochs,\n",
    "                                   validation_data = (x_test_normalize, test_y),\n",
    "                                   callbacks = [checkpoint, earlystop],\n",
    "                                   steps_per_epoch=steps_per_epoch,\n",
    "                                   validation_steps=validation_steps\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model\n",
      "45/45 [==============================] - 2s 34ms/step\n",
      "Test loss: 0.9972473343213399\n",
      "Test accuracy: 0.6222222288449605\n"
     ]
    }
   ],
   "source": [
    "# loading save model\n",
    "print('Loading trained model')\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Score trained model\n",
    "scores = model.evaluate(x_test_normalize, test_y, verbose = 1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
